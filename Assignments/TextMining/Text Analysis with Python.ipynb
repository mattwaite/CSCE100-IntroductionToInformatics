{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text analysis with Python\n",
    "\n",
    "Gigantic amounts of text is created every day. With software, we can now make it data. \n",
    "\n",
    "YOU MUST DO THIS ON THE COMMAND LINE FIRST, BEFORE STARTING JUPYTER NOTEBOOK:\n",
    "\n",
    "`pip install -U textblob`\n",
    "\n",
    "Next you'll want to find that `unlcrime.csv` file and put it in the same place you have this notebook in. For most of you, that will be in your downloads folder. If it's aready there -- and it very well may be -- then you're good to go. \n",
    "\n",
    "After that, start Jupyter Notebook.\n",
    "\n",
    "Our first step is always to import the libraries we need. In this case, we're importing textblob and csv, because we'll need it to read the data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import textblob, csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step to moving to meaningful data analysis is to get the csv file into a text file for us to use. First, we open the csv file, and we open a text file that we can write to. Then we loop through the csv, writing out the narratives for each incident in 2016 to that text file. Why only 2016? I tried doing this with all the years and it took forever on a reasonably decent machine. So this will give you a flavor of what can be done without killing your computer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unl = csv.reader(open(\"unlcrime.csv\", \"r\"), dialect=\"excel\")\n",
    "file = open(\"unlnarratives.txt\", \"w\") \n",
    "\n",
    "for row in unl:\n",
    "    if row[11] == \"2015\":\n",
    "        file.write(row[10]+\"\\n\")\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with a file, we can open it back up, read it and then turn it into something called a TextBlob, which the textblob library needs to work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(\"unlnarratives.txt\", \"r\")\n",
    "text = file.read()\n",
    "blob = textblob.TextBlob(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the most simple things we can do with text analysis is figure out what we have. For instance, we can get all nouns out of the incidents data like this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7240"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = blob.noun_phrases\n",
    "\n",
    "len(nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there's 6,533 noun phrases in the data. But how many words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40634"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = blob.words\n",
    "\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in a year, UNLPD wrote 32,229 words about crimes, mostly in single sentence descriptions on what went on. \n",
    "\n",
    "### Your turn\n",
    "\n",
    "Using [noun phrase and word count frequencies](https://textblob.readthedocs.io/en/dev/quickstart.html#get-word-and-noun-phrase-frequencies), what questions might you ask of this data? What would you want to know when it comes to words used by UNL police? How would you express that in code here? \n",
    "\n",
    "For the assignment, you must formulate a question that can be answered with noun phrase and word count frequencies. Then you must answer it with code. Turn in this notebook to the assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many times does drone appear? \n",
    "\n",
    "blob.word_counts['drone']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentences and sentiment\n",
    "\n",
    "Along with nouns and words, you can also get sentences. And with sentences, we can get to sentiment analysis. TextBlob has a built in sentiment classifier, and the ability to build your own. Let's test it out using the first 10 sentences of the UNLPD data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = blob.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensentences = sentences[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "Sentiment(polarity=0.0, subjectivity=0.05)\n",
      "Sentiment(polarity=0.0, subjectivity=0.5)\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "Sentiment(polarity=-0.175, subjectivity=0.45)\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "Sentiment(polarity=0.1, subjectivity=0.4)\n"
     ]
    }
   ],
   "source": [
    "for sentence in tensentences:\n",
    "    print(sentence.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BrAC 0.222.\n",
      "Malfunctioning steam pipe caused the Alarm in the building to go off.\n",
      "Turned over to UNL maintenance.\n",
      "A non-UNL affiliate was contacted on a traffic stop and subsequently cited and released for One headlight at night and Possess loaded shotgun on highway.\n",
      "A non-UNL affiliate was cited and released for Fictitious Plates, Open Title, No Valid Registration, DUS, and No Proof of Insurance.\n",
      "Vehicle was towed to Capitol Towing.\n",
      "Officers responded to a general fire alarm at Theta Xi which was found to be caused by a pipe that had broken.\n",
      "UNLPD Ofc.\n",
      "assisted LPD with UNL video footage from a robbery which just occurred near East Campus.\n"
     ]
    }
   ],
   "source": [
    "for sentence in tensentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn\n",
    "\n",
    "Here's a textblob of the last 10 tweets from Donald Trump. Rate each for polarity -- -1 is perfectly negative and +1 is perfectly positive -- and on subjectivity, where 0 is objective and 1 is subjective. Then run textblob's sentiment analysis and compare yours to its. How did you do? What's the problem with all of this? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = textblob.TextBlob(\n",
    "    \"Big vote tomorrow in the House. Tax cuts are getting close! \"\n",
    "    \"Why are Democrats fighting massive tax cuts for the middle class and business (jobs)? The reason: Obstruction and Delay! \"\n",
    "    \"It is actually hard to believe how naive (or dumb) the Failing @nytimes is when it comes to foreign policy...weak and ineffective! \"\n",
    "    \"...They should realize that these relationships are a good thing, not a bad thing. The U.S. is being respected again. Watch Trade! \"\n",
    "    \"The failing @nytimes hates the fact that I have developed a great relationship with World leaders like Xi Jinping, President of China. \"\n",
    "    \"Do you think the three UCLA Basketball Players will say thank you President Trump? They were headed for 10 years in jail! \"\n",
    "    \"While in the Philippines I was forced to watch @CNN, which I have not done in months, and again realized how bad, and FAKE, it is. Loser! \"\n",
    "    \".@foxandfriends will be showing much of our successful trip to Asia, and the friendships & benefits that will endure for years to come! \"\n",
    "    \"Our great country is respected again in Asia. You will see the fruits of our long but successful trip for many years to come! \"\n",
    "    \"Just returned from Asia after 12 very successful days. Great to be home! \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.0, subjectivity=0.1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = textblob.TextBlob(\"China is sending an Envoy and Delegation to North Korea - A big move, we'll see what happens!\")\n",
    "\n",
    "today.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big vote tomorrow in the House. Sentiment(polarity=0.0, subjectivity=0.1)\n",
      "Tax cuts are getting close! Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "Why are Democrats fighting massive tax cuts for the middle class and business (jobs)? Sentiment(polarity=0.0, subjectivity=0.5)\n",
      "The reason: Obstruction and Delay! Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "It is actually hard to believe how naive (or dumb) the Failing @nytimes is when it comes to foreign policy...weak and ineffective! Sentiment(polarity=-0.2807291666666667, subjectivity=0.5416666666666666)\n",
      "...They should realize that these relationships are a good thing, not a bad thing. Sentiment(polarity=0.5249999999999999, subjectivity=0.6333333333333333)\n",
      "The U.S. is being respected again. Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "Watch Trade! Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "The failing @nytimes hates the fact that I have developed a great relationship with World leaders like Xi Jinping, President of China. Sentiment(polarity=0.45, subjectivity=0.525)\n",
      "Do you think the three UCLA Basketball Players will say thank you President Trump? Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "They were headed for 10 years in jail! Sentiment(polarity=-0.125, subjectivity=0.0)\n",
      "While in the Philippines I was forced to watch @CNN, which I have not done in months, and again realized how bad, and FAKE, it is. Sentiment(polarity=-0.5, subjectivity=0.6222222222222222)\n",
      "Loser! Sentiment(polarity=0.0, subjectivity=0.0)\n",
      ". Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "@foxandfriends will be showing much of our successful trip to Asia, and the friendships & benefits that will endure for years to come! Sentiment(polarity=0.56875, subjectivity=0.575)\n",
      "Our great country is respected again in Asia. Sentiment(polarity=0.8, subjectivity=0.75)\n",
      "You will see the fruits of our long but successful trip for many years to come! Sentiment(polarity=0.44166666666666665, subjectivity=0.6166666666666667)\n",
      "Just returned from Asia after 12 very successful days. Sentiment(polarity=0.9750000000000001, subjectivity=1.0)\n",
      "Great to be home! Sentiment(polarity=1.0, subjectivity=0.75)\n"
     ]
    }
   ],
   "source": [
    "sentences = tweets.sentences\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(sentence, sentence.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "1. Knowing what you know about algorithms, what inputs do you think there are for sentiment analysis?  \n",
    "2. What problems might there be with those inputs? [Hint](https://www.engadget.com/2017/10/25/googles-sentiment-analysis-api-is-just-as-biased-as-humans/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
